{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the iris flower dataset from the following URL: https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csvLinks to an external site. and assign it to a Pandas DataFrame as you learned in tutorial Lab2-3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "X = iris_df[feature_cols]  \n",
    "y = iris_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into testing and training sets with the following parameters: test_size=0.4, random_state=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a KNN object with K=3, train it on the training set and test it on the testing set. Then, calculate the accuracy of your prediction as you learned in Lab3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat part (c) for K=1, K=5, K=7, K=11, K=15, K=27, K=59 (you can simply use a “for loop,” and save the final accuracy results in a list). Does the accuracy always get better by increasing the value K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95, 0.9833333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9166666666666666, 0.8166666666666667]\n"
     ]
    }
   ],
   "source": [
    "list_k = [1,5,7,11,15,27,59]\n",
    "list_accuracy = []\n",
    "for k in list_k:\n",
    "    temp_k = k\n",
    "    knn = KNeighborsClassifier(n_neighbors=temp_k) \n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    list_accuracy.append(accuracy)\n",
    "print(list_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list we can observe that increasing the value of k will lower accuracy after k = 5 is used. Therefor accuracy doesnt always get better while increasing k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose that we would like to make prediction based on only ONE single feature. To find the best single feature, we have to try every feature individually. In other word, we have to repeat part (c) with K=3, four times (each time using only one of the 4 features), and compute the accuracy each time. Then, check the accuracies. \n",
    "Which individual feature provide the best accuracy (the best feature)?  Which one is the second best feature? (Note: you have to train, test, and evaluate your model 4 times, each time on a dataset including only one of the features, and save the final accuracy results in a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6666666666666666, 0.55, 0.95, 0.95]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "list_accuracy2 = [] \n",
    "\n",
    "for i in range(4):\n",
    "    X = iris_df[[feature_cols[i]]]  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    list_accuracy2.append(accuracy)\n",
    "print(list_accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list there exists a tie between features 3 and 4 (petal_length and petal_width)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to repeat part (e), this time using two features. you have to train, test, and evaluate your model for 6 different cases: using (1st and 2nd features), (1st and 3rd features), (1st and 4th  features), (2nd  and 3rd  features), (2nd and 4th features), (3rd and 4th  features)!    \n",
    "Which “feature pair” provides the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7833333333333333, 0.9833333333333333, 0.95, 0.9833333333333333, 0.95, 0.9666666666666667]\n"
     ]
    }
   ],
   "source": [
    "list_features = [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3)]\n",
    "list_accuracy3 = [] \n",
    "    \n",
    "for i, j in list_features:\n",
    "    X = iris_df[[feature_cols[i],feature_cols[j]]]  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    list_accuracy3.append(accuracy)\n",
    "print(list_accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more we have a tie between the pair of feature (0,2) and (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big Question: Does the “best feature pair” from part (f) contain of both “first best feature” and “second best feature” from part (e)? In other word, can we conclude that the “best two features” for classification are the first best feature along with the second best feature together?\n",
    "\n",
    " Optional Question: Justify your answer for part (g)! If yes, why?  If no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best featured pairs only include one of the two best features. Because of this we can not conclude that the “best two features” for classification are the first best feature along with the second best feature together. \n",
    "\n",
    "We can justify this answer by observing the pattern of accuracy. We see the accuracy is better with a pair of sepal feature and petal feature. So there is a corellation to being able to predict the species of iris accurately, with any feature of sepal and the petal length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "224d6d3f3aaf7ad0e49846411ffcb67dbd8af7422c292e49fb0f968a347fb2c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
